```{r setup, cache=FALSE, include=FALSE}
devtools::load_all()
is.html = !is.null(output) && output == "html"
only.in.html = "*This chapter is currently only available in this web version. ebook and print will follow.*"

devtools::install_github("viadee/anchorsOnR")
install.packages("../pkg/sbrl_1.2.tar.gz", repos = NULL, type = "source")
```


# บทนำ {-}
```{r cover, cache=FALSE, eval = is.html, out.width=500, fig.align="center"}
knitr::include_graphics('images/title_page.jpg', dpi = NA)
```

จักรกลเรียนรู้มีประโยชน์เป็นอย่างมากในการใช้ปรับปรุงผลิตภัณฑ์ กระบวนการ และการใช้งานในการวิจัย
หนังสือเล่มนี้กล่าวถึงกลไกในการแปลความจักรกลเรียนรู้และผลลัพธ์จากการคาดเดาของมัน

หนังสือเล่มนี้เริ่มต้นด้วยการอธิบายแนวคิดของการแปลความได้ คุณจะได้เริ่มเรียนรู้เกี่ยวกับ**แบบจำลองแปลความได้** ซึ่งโดยมากเป็นแบบจำลองที่ไม่ซับซ้อน เช่นต้นไม้ตัดสินใจ (decision trees) กฎการตัดสินใจ (decision rules) และการถดถอยเชิงเส้น (linear regression)
และส่วนหลังในหนังสือพูดถึงขั้นตอนวิธีในการ**แปลความแบบจำลองชนิดกล่องดำ (black box model)** ซึ่งสามารถใช้ได้กับแบบจำลองใดๆ (model-agnostic) อาทิการคำนวณค่าความสำคัญของคุณลักษณะ (feature importance) และค่าผลกระทบสะสม (accumulated local effects) รวมถึงการอธิบายผลการคาดเดาจุดใดจุดหนึ่งผ่านขั้นตอนวิธีเช่น Shapley Values และ LIME

ในหนังสือเล่มนี้ เราจะพูดถึงขั้นตอนวิธีในการแปลความทั้งในแง่รายละเอียดทางเทคนิกและข้อจำกัด เช่นว่า
ขั้นตอนวิธีเหล่านี้มีวิธีการทำงานเบื้องหลังอย่างไร
มีข้อดีหรือข้อเสียอย่างไร
และเราจะแปลความหมายของผลลัพธ์อย่างไร
โดยที่เป้าหมายของหนังสือเล่มนี้คือเพื่อให้ผู้อ่านสามารถเลือกขั้นตอนวิธีการแปลความไปใช้กับงานจักรกลเรียนรู้ที่ผู้อ่านกำลังทำได้อย่างเหมาะสม

แบบจำลองที่ใช้ในการยกตัวอย่างภายในหนังสือเล่มนี้ส่วนมากเป็นแบบจำลองบนข้อมูลโครงสร้างตาราง (กล่าวคือเป็นข้อมูลที่มีโครงสร้างตายตัว) โดยจะไม่ได้กล่าวถึงแบบจำลองสำหรับการมองเห็นของคอมพิวเตอร์ (computer vision) และการประมวลผลภาษาธรรมชาติ (natural language processing) มากนัก
หนังสือเล่มนี้เหมาะสำหรับผู้ต้องการนำจักรกลเรียนรู้ไปใช้งานจริง (machine learning practitioner) นักวิทยาศาสตร์ข้อมูล (data scientist) นักสถิติ และผู้ที่สนใจการทำให้แบบจำลองจักรกลเรียนรู้แปลความไดั


`r if(is.html){"คุณสาามารถซื้อหนังสือเล่มนี้ (ฉบับภาษาอังกฤษ) ในรูปแบบไฟล์ PDF และ e-book ได้ผ่านเว็บไซต์ [leanpub.com](https://leanpub.com/interpretable-machine-learning)."}`

`r if(is.html){"คุณสามารถซื้อหนังสือเล่มนี้ในแบบฉบับพิมพ์ได้ที่ [ lulu.com](http://www.lulu.com/shop/christoph-molnar/interpretable-machine-learning/paperback/product-24036234.html)."}`

**เกี่ยวกับผู้เขียน (ฉบับภาษาอังกฤษ):** ผมชื่อคริสโตเฟอร์ โมลนาร์ (Christoph Molnar) เป็นนักสถิติและนักจักรกลเรียนรู้
เป้าหมายของผมคือทำให้แบบจำลองจักรกลเรียนรู้แปลความได้

อีเมล: christoph.molnar.ai@gmail.com

เว็บไซต์: [https://christophm.github.io/](https://christophm.github.io/)

มาฟอลโลว์ทวิตเตอร์ได้นะ! [\@ChristophMolnar](https://twitter.com/ChristophMolnar)

ออกแบบหน้าปกโดย [\@YvonneDoinel](https://twitter.com/YvonneDoinel)


`r if(is.html){"![Creative Commons License](images/by-nc-sa.png)"}`

`r if(is.html){"หนังสือเล่มนี้ใช้สัญญาอนุญาต [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."}`



# Preface by the Author {-}

This book started as a side project when I was working as a statistician in clinical research.
I worked 4 days a week, and on my "day off" I worked on side projects.
Eventually, interpretable machine learning became one of my side projects.
At first I had no intention of writing a book.
Instead, I was simply interested in finding out more about interpretable machine learning and was looking for good resources to learn from.
Given the success of machine learning and the importance of interpretability, I expected that there would be tons of books and tutorials on this topic.
But I only found the relevant research papers and a few blog posts scattered around the internet, but nothing with a good overview.
No books, no tutorials, no overview papers, nothing.
This gap inspired me to start this book.
I ended up writing the book I wished was available when I began my study of interpretable machine learning.
My intention with this book was twofold: to learn for myself and to share this new knowledge with others.

<!-- Introduction to Author -->
I received my bachelor's and master's degree in statistics at the LMU Munich, Germany.
Most of my knowledge about machine learning was self-taught through online courses, competitions, side projects and professional activities.
My statistical background was an excellent basis for getting into machine learning, and especially for interpretability.
In statistics, a major focus is on building interpretable regression models.
After I finished my master's degree in statistics, I decided not to pursue a PhD, because I did not enjoy writing my master's thesis.
Writing just stressed me out too much.
So I took jobs as data scientist in a Fintech start-up and as statistician in clinical research.
After these three years in industry I started writing this book and a few months later I started a PhD in interpretable machine learning.
By starting this book, I regained the joy of writing and it helped me to develop a passion for research.

This book covers many techniques of interpretable machine learning.
In the first chapters I introduce the concept of interpretability and motivate why interpretability is necessary.
There are even some short stories!
The book discusses the different properties of explanations and what humans think is a good explanation.
Then we will discuss machine learning models that are inherently interpretable, for example regression models and decision trees.
The main focus of this book is on model-agnostic interpretability methods.
Model-agnostic means that these methods can be applied to any machine learning model and are applied after the model has been trained.
The independence of the model makes model-agnostic methods very flexible and powerful.
Some techniques explain how individual predictions were made, like local interpretable model-agnostic explanations (LIME) and Shapley values.
Other techniques describe the average behavior of the model across a dataset.
Here we learn about the partial dependence plot, accumulated local effects, permutation feature importance and many other methods.
A special category are example-based methods that produce data points as explanations.
Counterfactual explanations, prototypes, influential instances and adversarial examples are example-based methods that are discussed in this book.
The book concludes with some reflections on what the future of interpretable machine learning might look like.

You do not have to read the book from cover to cover, you can jump back and forth and concentrate on the techniques that interest you most.
I only recommend that you start with the introduction and the chapter on interpretability.
Most chapters follow a similar structure and focus on one interpretation method.
The first paragraph summarizes the method.
Then I try to explain the method intuitively without relying on mathematical formulas.
Then we look at the theory of the method to get a deep understanding of how it works.
You will not be spared here, because the theory will contain formulas.
I believe that a new method is best understood using examples.
Therefore, each method is applied to real data.
Some people say that statistician are very critical people.
For me, this is true, because each chapter contains critical discussions about advantages and disadvantages of the respective interpretation method.
This book is not an advertisement for the methods, but it should help you decide whether a method works well for your application or not.
In the last section of each chapter, available software implementations are discussed.

Machine learning has received great attention from many people in research and industry.
Sometimes machine learning is overhyped in the media, but there are many real and impactful applications.
Machine learning is a powerful technology for products, research and automation.
Today machine learning is used, for example,  to detect fraudulent financial transactions, recommend movies to watch and classify images.
It is often crucial that the machine learning models are interpretable.
Interpretability helps the developer to debug and improve the model, build trust in the model, justify model predictions and gain insights.
The increased need for machine learning interpretability is a natural consequence of an increased use of machine learning.
This book has become a valuable resource for many people.
Teaching instructors use the book to introduce their students to the concepts of interpretable machine learning.
I received e-mails from various master and doctoral students who told me that this book was the starting point and most important reference for their theses.
The book has helped applied researchers in the field of ecology, finance, psychology, etc.  who use machine learning to understand their data.
Data scientists from industry told me that they use the "Interpretable Machine Learning" book for their work and recommend it to their colleagues.
I am happy that many people can benefit from this book and become experts in model interpretation.

I would recommend this book to practitioners who want an overview of techniques to make their machine learning models more interpretable.
It is also recommended to students and researchers (and anyone else) who is interested in the topic.
To benefit from this book, you should already have a basic understanding of machine learning.
You should also have a mathematical understanding at university entry level to be able to follow the theory and formulas in this book.
It should also be possible, however, to understand the intuitive description of the method at the beginning of each chapter without mathematics.

I hope you enjoy the book!

